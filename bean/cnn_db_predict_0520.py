# -*- coding: utf-8 -*-
"""CNN_DB_predict_0520.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18XzJGgArvSWuxTG-keMSClW0ZvgnCyMC
"""

# groups_folder_path = '/content/drive/My Drive/beans'
# categories = ["broken", "insect", "normal"] # 해당 이미지들이 들어가 있는 폴더명 넣어주기 
# num_classes = len(categories)

#pip install pymongo

#pip install sklearn

import torch
from torch.autograd import Variable 
import torch.nn as nn 
import torch.nn.functional as F 
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

import os 
from PIL import Image 
import numpy as np
import pandas as pd
from sklearn import datasets, model_selection

import pymongo
import gridfs 
from pymongo import MongoClient

groups_folder_path = './data'
categories = ["broken_rotated_data", "normal_rotated_data", "black_rotated_data"] # 해당 이미지들이 들어가 있는 폴더명 넣어주기

# # mongodb에서 사진 불러오기 
# # category 나눠서 들어갈 수 있도록 하기 



# if __name__ == '__main__' :
    
#     # connect to database 
#     client = MongoClient('127.0.0.1', 27017)

    


#     # read in the image 

#     for i,d in enumerate(categories):
#         files = os.listdir(groups_folder_path + '/'+ d)
#         database = client[d]

#         # create a new gridfs object
#         fs = gridfs.GridFS(database)

#         for f in files : 
#             img = open(groups_folder_path + '/'+ d +'/' + f, 'rb')
#             thedata = img.read()
#             # store the data in the database. 
#             # Returns the id of the file in gridFS 
#             stored = fs.put(thedata, filename = f)

    
    
    



#     # retrieve what was just stored 
#     #outputdata = fs.get(stored).read()

#     # create an output file and store the image in the output file 
#     # outfilename = './OpenCV/data/20200508_test1_sample1.jpg'
#     # output = open(outfilename, 'wb')
#     # output.write(outputdata)
#     # # close the output file 
#     # output.close()

#     # for experimental code restore to known state and close connection 

#     #fs.delete(stored)
#     #client.drop_database('example')
#     client.close()

# pip install StringIO

# import base64

# img = Image.open("./normal_data/normal_align_test_image/20200518_test_inadvance1_off.jpeg")
# img.size

import io

data = []
label = []

# groups_folder_path = './normal_data'
# categories = ["normal_align_test_image", "normal_processed_data", "normal_raw_data" ] # 해당 이미지들이 들어가 있는 폴더명 넣어주기 

if __name__ == '__main__' :  
  client = MongoClient('127.0.0.1', 27017)
  # read in the image 
  for i,d in enumerate(categories):
    database  = client[d]
    files     = os.listdir(groups_folder_path + '/'+ d)
    
    # create a new gridfs object
    fs        = gridfs.GridFS(database)

    #print( '->' +  d )
    for f in files : 
      #print( groups_folder_path + '/'+ d +'/' + f )
      fp         = open(groups_folder_path + '/'+ d +'/' + f, 'rb')
      # bytes로 읽는다
      thedata     = fp.read()            
      
      image = Image.open(io.BytesIO(thedata))
      #image.show()
      
      
      
      #print( type(thedata), len(thedata) )
      # 디비에 저장
      stored      = fs.put(thedata, filename = f)      
      # 디비에서 다시 읽는다
      outputdata  = fs.get(stored).read()
      #print( type(outputdata), len(outputdata) )
      #print( '-'*10 )
      
      thedata2 = Image.open(fp, mode='r')
      

      #thedata2 = Image.frombytes('RGB', (2160,2160), outputdata, 'raw')      
      # #thedata = Image.open(StringIO.StringIO(outputdata))
      # # 이미지 흑백으로 변경 
      img = thedata2.convert('L')
      # # 이미지를 28, 28로 일괄 리사이즈 
      resize_img = img.resize((28,28))
      black_resize_img = np.asarray(resize_img)
      # # 가공한 이미지 추가 
      data.append(black_resize_img)
      # # label : broken, insect, normal
      label.append(i)

      fp.close()
      #break


  client.close()

pd.DataFrame(data[0][0]).shape

data = np.array(data, dtype = 'float32')
label = np.array(label, dtype = 'int64')

train_X, test_X, train_Y, test_Y = model_selection.train_test_split(data, label, test_size = 0.1)

train_X = torch.from_numpy(train_X).float()
train_Y = torch.from_numpy(train_Y).long()

test_X = torch.from_numpy(test_X).float()
test_Y = torch.from_numpy(test_Y).long()

#train = TensorDataset(train_X, train_Y)
#train_loader = DataLoader(train, batch_size = 32, shuffle = True)

train_X

train_Y

test_X

test_Y

train_X.shape

train_Y.shape

test_X.shape

test_Y.shape

# 데이터 차원 맞추기
train_X = train_X.unsqueeze(1)
test_X = test_X.unsqueeze(1)

train_X.shape

test_X.shape

# 만약 GPU를 사용 가능하다면 device 값이 cuda가 되고, 아니라면 cpu가 됩니다.
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# 랜덤 시드 고정
torch.manual_seed(777)

# GPU 사용 가능일 경우 랜덤 시드 고정
if device == 'cuda':
    torch.cuda.manual_seed_all(777)

dataset = TensorDataset(train_X, train_Y)
type(dataset)

learning_rate = 0.001
training_epochs = 15
batch_size = 100

data_loader = torch.utils.data.DataLoader(dataset=dataset,
                                          batch_size=batch_size,
                                          shuffle=True,
                                          drop_last=True)

class CNN(torch.nn.Module):

    def __init__(self):
        super(CNN, self).__init__()
        # 첫번째층
        # ImgIn shape=(?, 28, 28, 1)
        #    Conv     -> (?, 28, 28, 32)
        #    Pool     -> (?, 14, 14, 32)
        self.layer1 = torch.nn.Sequential(
            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1 ),
            torch.nn.Tanh(),
            torch.nn.MaxPool2d(kernel_size=2, stride=2))

        # 두번째층
        # ImgIn shape=(?, 14, 14, 32)
        #    Conv      ->(?, 14, 14, 64)
        #    Pool      ->(?, 7, 7, 64)
        self.layer2 = torch.nn.Sequential(
            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            torch.nn.Tanh(),
            torch.nn.MaxPool2d(kernel_size=2, stride=2))

        # 전결합층 7x7x64 inputs -> 10 outputs
        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)

        # 전결합층 한정으로 가중치 초기화
        torch.nn.init.xavier_uniform_(self.fc.weight)

    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten
        out = self.fc(out)
        return out

# 모델을 정의합니다.

# CNN 모델 정의
model = CNN().to(device)
# 비용 함수와 옵티마이저를 정의합니다.

criterion = torch.nn.CrossEntropyLoss().to(device)    # 비용 함수에 소프트맥스 함수 포함되어져 있음.
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
# 총 배치의 수를 출력해보겠습니다.

total_batch = len(data_loader)
print('총 배치의 수 : {}'.format(total_batch))
# 총 배치의 수 : 600
# 총 배치의 수는 600입니다. 그런데 배치 크기를 100으로 했으므로 결국 훈련 데이터는 총 60,000개란 의미입니다. 이제 모델을 훈련시켜보겠습니다. (시간이 꽤 오래 걸립니다.)

model.train()

for epoch in range(training_epochs):
    
    avg_cost = 0
    
    for X, Y in data_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y는 레이블.
        # image is already size of (28x28), no reshape
        # label is not one-hot encoded
        X = X.to(device)
        Y = Y.to(device)

        optimizer.zero_grad()
        hypothesis = model(X)
        cost = criterion(hypothesis, Y)
        cost.backward()
        optimizer.step()

        avg_cost += cost / total_batch

    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))

# test dataset 만들기 
testset = TensorDataset(test_X, test_Y)
type(testset)

batch_size = 100

testloader = torch.utils.data.DataLoader(dataset=testset,
                                          batch_size=batch_size,
                                          shuffle=False,
                                          drop_last=True)

# 테스트 데이터로 모델 테스트 진행 
"""
https://wingnim.tistory.com/36
"""

model.eval()
test_loss = 0 
correct = 0

for data, target in testloader: 
    data = data.to(device)
    target = target.to(device) 
    

    output = model(data)

    # sum up batch loss 
    test_loss += criterion(output, target).data

    # get the index of the max log-probability 
    pred = output.data.max(1, keepdim = True)[1]
    correct += pred.eq(target.data.view_as(pred)).cpu().sum()

test_loss /= len(testloader.dataset)/batch_size

print('\nTest set : Average loss : {: .4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))

"""
https://medium.com/@trilliwon/pytorch-%E1%84%8B%E1%85%B5%E1%84%86%E1%85%B5%E1%84%8C%E1%85%B5-%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2-%E1%84%92%E1%85%A2%E1%84%87%E1%85%A9%E1%84%80%E1%85%B5-4ceab523cb66
"""

# # 테스트 데이터로 테스트 진행 

# categories = ["broken", "normal"]

# class_correct = list(0. for i in range(2))
# class_total = list(0. for i in range(2))

# with torch.no_grad():
#     for data in testloader:
#         images, labels = data 
#         outputs = net(images)
#         _, predicted = torch.max(outputs, 1) 
#         c = (predicted == labels).squeeze()
#         for i in range(4):
#              label = labels[i]
#              class_correct[label] += c[i].item()
#              class_total[label] += 1
# for i in range(10):
#     print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i]/class_total[i]))

# CNN 모델에 이미지 대입하여 예측결과 확인하기 
# 참고 사이트 

"""
https://github.com/MLlounge/ML-Project/blob/master/Basic%20Project/CNN%20-%20Distinguish%20language%20according%20to%20characters/CNN%20-%20Distinguish%20language%20according%20to%20characters.py
"""

"""
https://www.yceffort.kr/2019/01/30/pytorch-3-convolutional-neural-network(2)/
"""

"""
https://tutorials.pytorch.kr/beginner/blitz/cifar10_tutorial.html
"""


from PIL import Image 
import numpy as np 
#pre_img = Image.open("./broken_data/broken_data/broken_processed_data/20200519_12_broken_take14.jpg")
#pre_img = Image.open("./normal_data/normal_processed_data/20200518_14_normal_take6.jpg")
#pre_img = Image.open("./data/broken_rotated_data/20200519_0_broken_take1_final_45.jpg")
pre_img = Image.open("./data/black_rotated_data/20200521_0_black_take0_final_0.jpg")
pre_img = pre_img.convert('L')
      
# # 이미지를 28, 28로 일괄 리사이즈 
resized_pre_img = pre_img.resize((28,28))
np_pre_img = np.asarray(resized_pre_img)
np_pre_img = np.reshape(np_pre_img, [1,1,28,28])
#torch.Size([3056, 1, 28, 28])
#type(np_pre_img)

pre_X = torch.from_numpy(np_pre_img).float().to(device)
#pre_X
#pre_X.shape

result = torch.max(model(pre_X).data.to(device), 1)[1]

#print(result)
print("이 커피콩은 ",categories[result[0]], "입니다.")





































