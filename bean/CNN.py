# -*- coding: utf-8 -*-
"""CNN_DB_predict_0520.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18XzJGgArvSWuxTG-keMSClW0ZvgnCyMC
"""


#pip install pymongo

#pip install sklearn

import torch
from torch.autograd import Variable 
import torch.nn as nn 
import torch.nn.functional as F 
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

import os 
from PIL import Image 
import numpy as np
import pandas as pd
from sklearn import datasets, model_selection

import pymongo
import gridfs 
from pymongo import MongoClient

groups_folder_path = './data'
categories = ["broken_rotated_data", "normal_rotated_data", "black_rotated_data"] # 해당 이미지들이 들어가 있는 폴더명 넣어주기

import io

if __name__ == '__main__' :  
  client = MongoClient('127.0.0.1', 27017)
  # read in the image 
  for i,d in enumerate(categories):
    database  = client[d]
    files     = os.listdir(groups_folder_path + '/'+ d)
    
    # create a new gridfs object
    fs        = gridfs.GridFS(database)

    #print( '->' +  d )
    for f in files : 
      #print( groups_folder_path + '/'+ d +'/' + f )
      fp         = open(groups_folder_path + '/'+ d +'/' + f, 'rb')
      # bytes로 읽는다
      thedata     = fp.read()            
      
      image = Image.open(io.BytesIO(thedata))
      #image.show()
      
      
      
      #print( type(thedata), len(thedata) )
      # 디비에 저장
      stored      = fs.put(thedata, filename = f)      
      # 디비에서 다시 읽는다
      outputdata  = fs.get(stored).read()
      #print( type(outputdata), len(outputdata) )
      #print( '-'*10 )
      
      thedata2 = Image.open(fp, mode='r')
      

      #thedata2 = Image.frombytes('RGB', (2160,2160), outputdata, 'raw')      
      # #thedata = Image.open(StringIO.StringIO(outputdata))
      # # 이미지 흑백으로 변경 
      img = thedata2.convert('L')
      # # 이미지를 28, 28로 일괄 리사이즈 
      resize_img = img.resize((28,28))
      black_resize_img = np.asarray(resize_img)
      # # 가공한 이미지 추가 
      data.append(black_resize_img)
      # # label : broken, insect, normal
      label.append(i)

      fp.close()
      #break


  client.close()

pd.DataFrame(data[0][0]).shape

data = np.array(data, dtype = 'float32')
label = np.array(label, dtype = 'int64')

train_X, test_X, train_Y, test_Y = model_selection.train_test_split(data, label, test_size = 0.1)

train_X = torch.from_numpy(train_X).float()
train_Y = torch.from_numpy(train_Y).long()

test_X = torch.from_numpy(test_X).float()
test_Y = torch.from_numpy(test_Y).long()


# 데이터 차원 맞추기
train_X = train_X.unsqueeze(1)
test_X = test_X.unsqueeze(1)

# 만약 GPU를 사용 가능하다면 device 값이 cuda가 되고, 아니라면 cpu가 됩니다.
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# 랜덤 시드 고정
torch.manual_seed(777)

# GPU 사용 가능일 경우 랜덤 시드 고정
if device == 'cuda':
    torch.cuda.manual_seed_all(777)

dataset = TensorDataset(train_X, train_Y)
type(dataset)

learning_rate = 0.001
training_epochs = 15
batch_size = 100

data_loader = torch.utils.data.DataLoader(dataset=dataset,
                                          batch_size=batch_size,
                                          shuffle=True,
                                          drop_last=True)

class CNN(torch.nn.Module):

    def __init__(self):
        super(CNN, self).__init__()
        # 첫번째층
        # ImgIn shape=(?, 28, 28, 1)
        #    Conv     -> (?, 28, 28, 32)
        #    Pool     -> (?, 14, 14, 32)
        self.layer1 = torch.nn.Sequential(
            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1 ),
            torch.nn.Tanh(),
            torch.nn.MaxPool2d(kernel_size=2, stride=2))

        # 두번째층
        # ImgIn shape=(?, 14, 14, 32)
        #    Conv      ->(?, 14, 14, 64)
        #    Pool      ->(?, 7, 7, 64)
        self.layer2 = torch.nn.Sequential(
            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            torch.nn.Tanh(),
            torch.nn.MaxPool2d(kernel_size=2, stride=2))

        # 전결합층 7x7x64 inputs -> 10 outputs
        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)

        # 전결합층 한정으로 가중치 초기화
        torch.nn.init.xavier_uniform_(self.fc.weight)

    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten
        out = self.fc(out)
        return out

# 모델을 정의합니다.

# CNN 모델 정의
model = CNN().to(device)
# 비용 함수와 옵티마이저를 정의합니다.

criterion = torch.nn.CrossEntropyLoss().to(device)    # 비용 함수에 소프트맥스 함수 포함되어져 있음.
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
# 총 배치의 수를 출력해보겠습니다.

total_batch = len(data_loader)
print('총 배치의 수 : {}'.format(total_batch))
# 총 배치의 수 : 600
# 총 배치의 수는 600입니다. 그런데 배치 크기를 100으로 했으므로 결국 훈련 데이터는 총 60,000개란 의미입니다. 이제 모델을 훈련시켜보겠습니다. (시간이 꽤 오래 걸립니다.)

model.train()

for epoch in range(training_epochs):
    
    avg_cost = 0
    
    for X, Y in data_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y는 레이블.
        # image is already size of (28x28), no reshape
        # label is not one-hot encoded
        X = X.to(device)
        Y = Y.to(device)

        optimizer.zero_grad()
        hypothesis = model(X)
        cost = criterion(hypothesis, Y)
        cost.backward()
        optimizer.step()

        avg_cost += cost / total_batch

    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))

# test dataset 만들기 
testset = TensorDataset(test_X, test_Y)
type(testset)

batch_size = 100

testloader = torch.utils.data.DataLoader(dataset=testset,
                                          batch_size=batch_size,
                                          shuffle=False,
                                          drop_last=True)

# 테스트 데이터로 모델 테스트 진행 
"""
https://wingnim.tistory.com/36
"""

model.eval()
test_loss = 0 
correct = 0

for data, target in testloader: 
    data = data.to(device)
    target = target.to(device) 
    

    output = model(data)

    # sum up batch loss 
    test_loss += criterion(output, target).data

    # get the index of the max log-probability 
    pred = output.data.max(1, keepdim = True)[1]
    correct += pred.eq(target.data.view_as(pred)).cpu().sum()

test_loss /= len(testloader.dataset)/batch_size

print('\nTest set : Average loss : {: .4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(test_loss, correct, len(testloader.dataset), 100. * correct / len(testloader.dataset)))


from PIL import Image 
import numpy as np 
pre_img = Image.open("./data/black_rotated_data/20200521_0_black_take0_final_0.jpg")
pre_img = pre_img.convert('L')
      
# # 이미지를 28, 28로 일괄 리사이즈 
resized_pre_img = pre_img.resize((28,28))
np_pre_img = np.asarray(resized_pre_img)
np_pre_img = np.reshape(np_pre_img, [1,1,28,28])
#torch.Size([3056, 1, 28, 28])
#type(np_pre_img)

pre_X = torch.from_numpy(np_pre_img).float().to(device)

result = torch.max(model(pre_X).data.to(device), 1)[1]

print("이 커피콩은 ",categories[result[0]], "입니다.")





































